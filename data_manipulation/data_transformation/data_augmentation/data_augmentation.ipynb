{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcPj1JlAdkd9"
      },
      "outputs": [],
      "source": [
        "# GPU llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
        "!pip install huggingface_hub\n",
        "!pip install llama-cpp-python==0.1.78\n",
        "!pip install numpy==1.23.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "flcl3M7mfdxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avESuOB7gXzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/cleaned_data.csv')"
      ],
      "metadata": {
        "id": "jDQMROiRgXpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format"
      ],
      "metadata": {
        "id": "Mha7XEoTfd4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXxKxDmefd2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ],
      "metadata": {
        "id": "z2W77COxfdqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "lcpp_llm = None\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
        "    )"
      ],
      "metadata": {
        "id": "Ph9WkjYCfdnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yz7GpANkfyqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to drop\n",
        "columns_to_drop = ['Rating', 'Additional Tags']\n",
        "\n",
        "# Use the drop method to remove the specified columns\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Save the DataFrame back to the CSV file without the dropped columns\n",
        "# df.to_csv('your_updated_file.csv', index=False)"
      ],
      "metadata": {
        "id": "JdM1ryx9fyiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yxUHh4Pg7aVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_data = df['Content']"
      ],
      "metadata": {
        "id": "YMaAo9KI7aTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_content = []\n",
        "for i in column_data:\n",
        "  sentence = str(i)[:500]\n",
        "  prompt = f\"\"\"\n",
        "  Generate the modified version of the given story:\n",
        "  {sentence}\n",
        "  \"\"\"\n",
        "  prompt_template=f'''SYSTEM: You are a helpful and creative story generator assistant that reduces the given story into meaningful story in the word count range seventy to eighty.\n",
        "\n",
        "  USER: {prompt}\n",
        "\n",
        "  ASSISTANT:\n",
        "  '''\n",
        "  response=lcpp_llm(prompt=prompt_template, max_tokens=250, temperature=0.5, top_p=0.95,\n",
        "                  repeat_penalty=1.2, top_k=150,\n",
        "                  echo=True)\n",
        "  text = response[\"choices\"][0][\"text\"]\n",
        "  modified_content.append(text)\n"
      ],
      "metadata": {
        "id": "BJlRkgn_7aQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_content(text):\n",
        "    # Split the text into sentences using periods as delimiters\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    # Initialize variables to keep track of the word count and the selected sentences\n",
        "    selected_sentences = []\n",
        "    current_word_count = 0\n",
        "\n",
        "    # Iterate through the sentences and add them to the selected_sentences list until reaching almost 75 words\n",
        "    for sentence in sentences:\n",
        "        # Count the words in the current sentence by splitting on spaces\n",
        "        words = sentence.strip().split()\n",
        "        word_count = len(words)\n",
        "\n",
        "        # If adding the current sentence doesn't exceed 75 words, add it to the selected_sentences\n",
        "        if current_word_count + word_count <= 75:\n",
        "            selected_sentences.append(sentence)\n",
        "            current_word_count += word_count\n",
        "        else:\n",
        "            # Break the loop if adding the sentence would exceed 75 words\n",
        "            break\n",
        "\n",
        "    # Join the selected sentences to create a text with nearly 75 words\n",
        "    result_text = '.'.join(selected_sentences)\n",
        "\n",
        "    return result_text"
      ],
      "metadata": {
        "id": "NhPgCVyl7aMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Modified'] = df['Content'].apply(process_content)"
      ],
      "metadata": {
        "id": "vgvhZhFl7aKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Modified'], inplace=True)"
      ],
      "metadata": {
        "id": "vdFRpf5Ba5FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_data = df['Modified']"
      ],
      "metadata": {
        "id": "O5zD1a7bfykl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genres = []\n",
        "for i in column_data:\n",
        "  sentence = str(i)\n",
        "  prompt = f\"\"\"\n",
        "  Write the genre in a single word:\n",
        "  {sentence}\n",
        "  \"\"\"\n",
        "  prompt_template=f'''SYSTEM: You are a helpful and creative story classifier assistant that gives a one word genre from the given story.\n",
        "\n",
        "  USER: {prompt}\n",
        "\n",
        "  ASSISTANT:\n",
        "  '''\n",
        "  response=lcpp_llm(prompt=prompt_template, max_tokens=30, temperature=0.5, top_p=0.95,\n",
        "                  repeat_penalty=1.2, top_k=150,\n",
        "                  echo=True)\n",
        "  genre = response[\"choices\"][0][\"text\"]\n",
        "  pattern = r'ASSISTANT:\\n(.*?)(?=\\n)'\n",
        "  matches = re.findall(pattern, genre, re.DOTALL)\n",
        "  for match in matches:\n",
        "    genres.append(match.strip())"
      ],
      "metadata": {
        "id": "kFUQlzfrfyW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Genre'] = genres"
      ],
      "metadata": {
        "id": "pCuC_GEAfyfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_data = df['Modified']"
      ],
      "metadata": {
        "id": "If0LWb3a7Z9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_list = []\n",
        "for i in column_data:\n",
        "  story = i\n",
        "  prompt = f\"\"\"\n",
        "  Write the context of the given short story in about 5 words, without saying the name of any characters and just giving a general outline of the situation ;\n",
        "  {story}\n",
        "  \"\"\"\n",
        "  prompt_template=f'''SYSTEM: You are a helpful and creative context generator assistant. You produce only the output without saying useless formalities.\n",
        "\n",
        "  USER: {prompt}\n",
        "\n",
        "  ASSISTANT:\n",
        "  '''\n",
        "  response=lcpp_llm(prompt=prompt_template, max_tokens=30, temperature=1, top_p=0.95,\n",
        "                  repeat_penalty=1.2, top_k=150,\n",
        "                  echo=True)\n",
        "  context = response[\"choices\"][0][\"text\"]\n",
        "  print(response[\"choices\"][0][\"text\"])\n",
        "  assistant_response = response[\"choices\"][0][\"text\"].split(\"ASSISTANT:\")[1].strip()\n",
        "  context_list.append(assistant_response)"
      ],
      "metadata": {
        "id": "Pm6GuoKp7Z6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Context'] = context_list"
      ],
      "metadata": {
        "id": "gMzrAa9b7Z42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_non_alphanumeric(text):\n",
        "    # Use regular expression to remove non-alphanumeric characters\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)"
      ],
      "metadata": {
        "id": "2kSrCHjA7Z20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to a specific column (e.g., 'your_column_name')\n",
        "df['Context'] = df['Context'].apply(remove_non_alphanumeric)"
      ],
      "metadata": {
        "id": "4erqEuOXbyPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/output.csv\")"
      ],
      "metadata": {
        "id": "m3TaimsE7Z0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the formatted rows\n",
        "formatted_rows = []\n",
        "\n",
        "# Iterate through the rows of the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    # Extract the \"genre\" and \"content\" values\n",
        "    genre = row['Genre']\n",
        "    content = row['Modified']\n",
        "    context = row['Context']\n",
        "\n",
        "    # Create the formatted text\n",
        "    formatted_text = f\"### Human: Create a short story of about seventy-five words on the genre: {genre} and context: {context} . ### Assistant: {content}\"\n",
        "\n",
        "    # Append the formatted text to the list\n",
        "    formatted_rows.append(formatted_text)"
      ],
      "metadata": {
        "id": "6OgB_Y_O7Zyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'] = formatted_rows\n",
        "df = df.drop(columns=['URL', 'Genre', 'Modified', 'Context'])\n",
        "df.to_csv('/content/train.csv', index=False)"
      ],
      "metadata": {
        "id": "ibHYpJDP7Zv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MaDlU6Kc7ZtL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}